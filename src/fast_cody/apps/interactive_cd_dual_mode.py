import os
import numpy as np
import scipy as sp
import igl
import json
from os.path import basename, splitext
import time

import fast_cd_pyb as fcd
import fast_cody as fc


def interactive_cd_dual_mode(msh_file=None, V=None, T=None, Ws=None, l=None, mu=1e4, rho=1e3,
                             num_modes=16, num_clusters=100,
                             constraint_enforcement="optimal",
                             cache_dir=None, results_dir=None, read_cache=False,
                             texture_png=None, texture_obj=None,
                             movement_speed=0.05, rotation_speed=0.02, camera_distance=8.0,
                             background_color=None, lighting_factor=None):
    """
    Runs an interactive fast CD simulation with dual control modes:
    1. Third-Person Drag Mode: Click and drag the fish with mouse (same as affine handle)
    2. First-Person Control Mode: Control the fish with WASD keyboard, camera follows behind

    Parameters
    ----------
    msh_file : str
        path to Tet mesh .msh file (usually generated by TetWild). If None, expects V and T to be provided.
    V : (n, 3) float numpy array
        n x 3 vertex positions. If None, expects msh_file to be provided.
    T : (t, 4) int numpy array.
        t x 4 tet indices. If None, expects msh_file to be provided.
    Ws : (n, m) float numpy array
        n x m skinning weights used for simulation. If None, recomputed on the fly
    l : (t, 1) int numpy array
        T x 1  per-tet cluster indices. if None, recomputed on the fly.
    num_modes : int
        if Ws is None, number of skinning modes to compute
    num_clusters : int
        if l is None, number of skinning clusters to compute.
    constraint_enforcement : str
        {"project", "optimal"}.
        if "optimal", performs the full constrained GEVP described in the paper.
    cache_dir : str
        directory where results are stored and where cache is stored. if None, then
    read_cache : bool
        whether to read skinning modes from cache or not (default=False)
    texture_obj : str
        directory pointing towards a .obj file of the surface mesh
        containing the UV map required for texture mapping. If None and if texture_png is None, then no texturing is applied.
    texture_png : str
        directory pointing towards a .png file of the surface texture.
        if None and if texture_obj is None, then no texturing is applied.
    movement_speed : float
        speed of fish movement in first-person mode (default=0.05)
    rotation_speed : float
        speed of fish rotation in first-person mode (default=0.02)
    camera_distance : float
        distance of camera behind fish in first-person mode (default=3.0)
    background_color : (3,) float numpy array, optional
        RGB background color (0-1 range). If None, uses water-like blue [0.1, 0.4, 0.6] (default=None)
    lighting_factor : float, optional
        Lighting factor for underwater effect (0-1). If None, uses 0.7 for underwater feel (default=None)


    Examples
    --------
    >>> import fast_cody as fcd
    >>> fcd.apps.interactive_cd_dual_mode()
    """

    if msh_file is not None:
        [V, F, T] = fcd.readMSH(msh_file)
    elif msh_file is None and (V is None and T is None):
        msh_file = fc.get_data("./cd_fish.msh")
        [V, F, T] = fcd.readMSH(msh_file)
    else:
        assert(V is not None and T is not None and "Must provide either msh_file or V and T")

    if texture_png is None or texture_obj is None:
        if msh_file == fc.get_data("./cd_fish.msh"):
            texture_png = fc.get_data("./cd_fish_tex.png")
            texture_obj = fc.get_data("./cd_fish_tex.obj")

    if cache_dir is None:
        cache_dir = "./cache/"
    os.makedirs(cache_dir, exist_ok=True)

    [V, so, to] = fcd.scale_and_center_geometry(V, 1, np.array([[0, 0,  0.]])) #center to unit height and about origin

    Wp = np.ones((V.shape[0], 1)) #single handle skinning weight
    J = fc.lbs_jacobian(V, Wp)


    if Ws is None or l is None:
        C = fc.complementary_constraint_matrix(V, T, J, dt=1e-3)
        C2 = fc.lbs_weight_space_constraint(V, C)
        [B, l, Ws] = fc.skinning_subspace(V, T, num_modes, num_clusters, C=C2, read_cache=read_cache,
                                         cache_dir=cache_dir, constraint_enforcement=constraint_enforcement);
    else:
        assert (Ws is not None and l is not None and "Secondary skinning weights and clusters need both be specified")
        num_modes = Ws.shape[1]
        num_clusters = l.max() + 1

    sim = fc.fast_cd_sim(V, T, B, l, J, mu=mu, rho=rho, h=1e-2, cache_dir=cache_dir, read_cache=read_cache)

    # set sim state and initial rig parameters
    z0 = np.zeros((num_modes*12, 1))
    T0 = np.identity(4).astype(dtype=np.float32, order="F")
    p0 = T0[0:3, :].reshape((12, 1))
    st = fc.fast_cd_state(z0, p0)

    # Control mode: how the fish is controlled
    # 'keyboard' = WASD keyboard control
    # 'mouse' = mouse drag with guizmo (affine handle)
    control_mode = 'mouse'
    
    # Camera mode: camera perspective
    # 'first_person' = camera follows behind fish (close, above head)
    # 'third_person' = camera tracks fish from further away (better overview)
    camera_mode = 'third_person'
    
    # Key state tracking for keyboard control mode
    # We'll use a set to track which keys are currently active
    # Keys are added on press and should be removed on release, but since we don't have
    # key release events, we'll use a timeout-based approach
    active_keys = set()
    key_last_pressed = {}  # Track when keys were last pressed
    key_timeout = 2.0  # Consider key inactive after this many seconds without re-press (longer for smoother controls)
    
    last_update_time = time.time()
    
    # Acceleration-based movement system for smooth motion
    current_velocity = np.array([0.0, 0.0, 0.0])  # Current velocity vector (forward/back, left/right, up/down)
    acceleration_rate = 5.0  # How fast velocity increases (units per second^2)
    damping_factor = 0.85  # Velocity decay factor per frame (0-1, higher = less damping)
    max_velocity = movement_speed * 3.0  # Maximum velocity

    # Create viewer with custom shader
    vertex_shader_path = fc.get_shader("./vertex_shader_16.glsl")
    fragment_shader_path = fc.get_shader("./fragment_shader.glsl")
    viewer_base = fcd.fast_cd_viewer_custom_shader(vertex_shader_path, fragment_shader_path, 16, 16)
    
    # Set water-like background color (ocean blue/cyan)
    if background_color is None:
        # Default water color: deep ocean blue
        background_color = np.array([0.1, 0.4, 0.6])  # Deep ocean blue (RGB 0-1)
    else:
        background_color = np.array(background_color)
    viewer_base.set_background_color(background_color)
    
    # Adjust lighting for underwater effect (slightly dimmer, more diffuse)
    if lighting_factor is None:
        lighting_factor = 0.7  # Slightly reduced lighting for underwater feel
    viewer_base.set_lighting_factor(lighting_factor)
    
    print("=" * 60)
    print("DUAL MODE CONTROLS:")
    print("  CONTROL MODE (how to move the fish):")
    print("    K        Toggle between Keyboard and Mouse control")
    print("  CAMERA MODE (camera perspective):")
    print("    V        Toggle between First-Person and Third-Person camera")
    print("  OTHER:")
    print("    c        Toggle Secondary Motion")
    print("    g        Toggle Guizmo Widget Transform (Mouse control only)")
    print("")
    print("KEYBOARD CONTROL (WASD):")
    print("  W        Move forward")
    print("  S        Move backward")
    print("  A        Move left (horizontal)")
    print("  D        Move right (horizontal)")
    print("")
    print("MOUSE CONTROL:")
    print("  Use mouse to drag guizmo (affine handle) to move/rotate/scale fish")
    print("")
    print("CAMERA MODES:")
    print("  First-Person:  Camera close behind fish, above head")
    print("  Third-Person:  Camera further back for better overview")
    print("=" * 60)

    F, _, _ = igl.boundary_facets(T)
    vis_texture = False
    if texture_png is not None and texture_obj is not None:
        vis_texture = True

    if not vis_texture:
        viewer_base.set_mesh(V, F, 0)
        viewer_base.invert_normals(True, 0)
        color = np.array([144, 210, 236]) / 255.0
        viewer_base.set_color(color, 0)
        viewer_base.set_weights(Wp, Ws, 0)
    else:
        [Vf, TC, N, Ff, FTC, FN] = fcd.readOBJ_tex(texture_obj)
        if so is not None:
            Vf = Vf * so
        if to is not None:
            Vf = Vf - to

        P = fcd.prolongation(Vf, V, T)
        Pe = sp.sparse.kron(sp.sparse.identity(3), P)
        viewer_base.set_mesh(Vf, Ff, 0)
        viewer_base.set_texture(texture_png, TC, FTC, 0)
        Wp_tex = P @ Wp
        Ws_tex = P @ Ws
        viewer_base.set_weights(Wp_tex, Ws_tex, 0)
        viewer_base.set_show_lines(False, 0)
        viewer_base.set_face_based(False, 0)

    # NOTE: Reference objects are disabled to avoid memory issues
    # The viewer appears to only support mesh ID 0, and adding additional meshes causes crashes
    # The increased camera distance should still make rotation more visible
    # If reference objects are needed, they would need to be combined with the main mesh
    # or the viewer would need to be modified to support multiple meshes
    pass  # Reference objects temporarily disabled

    # Initialize guizmo
    transform_mode = "translate"
    
    def guizmo_callback_wrapper(A):
        nonlocal T0
        T0 = A
    
    # Initialize guizmo - visible by default since we start in mouse control mode
    viewer_base.init_guizmo(True, T0, guizmo_callback_wrapper, transform_mode)
    
    vis_cd = True
    guizmo_visible = True  # Initially visible since control_mode starts as 'mouse'

    def key_callback(key, modifier):
        nonlocal control_mode, camera_mode, transform_mode, guizmo_visible, vis_cd, active_keys, key_last_pressed
        nonlocal current_velocity, T0
        
        current_time = time.time()
        
        # Control mode toggle (K key) - Keyboard vs Mouse
        if key == ord('k') or key == ord('K'):
            control_mode = 'keyboard' if control_mode == 'mouse' else 'mouse'
            active_keys.clear()  # Clear active keys when switching control modes
            
            if control_mode == 'keyboard':
                # Switching to keyboard control: hide guizmo, reset velocity
                if hasattr(viewer_base, 'guizmo'):
                    viewer_base.guizmo.visible = False
                # Reset velocity for clean start
                current_velocity = np.array([0.0, 0.0, 0.0])
            else:
                # Switching to mouse control: show guizmo and sync it to current fish position
                if hasattr(viewer_base, 'guizmo'):
                    viewer_base.guizmo.visible = True
                    # Sync guizmo transform to current fish transform
                    viewer_base.guizmo.T = T0.copy()
                # Reset velocity
                current_velocity = np.array([0.0, 0.0, 0.0])
            
            print(f"Control mode: {control_mode}")
            return True
        
        # Camera mode toggle (V key) - First-Person vs Third-Person camera
        if key == ord('v') or key == ord('V'):
            camera_mode = 'first_person' if camera_mode == 'third_person' else 'third_person'
            print(f"Camera mode: {camera_mode}")
            return True
        
        # Toggle secondary motion (C key)
        if key == ord('c') or key == ord('C'):
            vis_cd = not vis_cd
            return True
        
        # Guizmo transform toggle (G key) - only in mouse control mode
        if (key == ord('g') or key == ord('G')) and control_mode == 'mouse':
            if transform_mode == "translate":
                transform_mode = "rotate"
            elif transform_mode == "rotate":
                transform_mode = "scale"
            elif transform_mode == "scale":
                transform_mode = "translate"
            viewer_base.change_guizmo_op(transform_mode)
            return True
        
        # Keyboard controls - track WASD keys (works in keyboard control mode)
        if control_mode == 'keyboard':
            key_char = chr(key).lower() if key < 256 else ''
            if key_char in ['w', 'a', 's', 'd']:
                active_keys.add(key_char)
                key_last_pressed[key_char] = current_time
                return True
        
        return False

    def update_keyboard_controls(dt):
        """Update fish transform based on WASD input with acceleration-based movement"""
        nonlocal T0, active_keys, key_last_pressed, key_timeout
        nonlocal current_velocity, control_mode
        
        current_time = time.time()
        
        # Remove keys that haven't been pressed recently (timeout-based key release detection)
        keys_to_remove = []
        for key in active_keys:
            if key in key_last_pressed:
                if current_time - key_last_pressed[key] > key_timeout:
                    keys_to_remove.append(key)
        for key in keys_to_remove:
            active_keys.discard(key)
        
        # Get current transform to extract orientation
        current_pos = T0[0:3, 3].copy()
        R = T0[0:3, 0:3].copy()  # Current rotation matrix
        
        # Calculate movement directions from current orientation
        # Forward is Z-axis column, Right is X-axis column, Up is Y-axis column
        forward_dir = R[:, 2].copy()  # Forward (Z-axis)
        right_dir = R[:, 0].copy()    # Right (X-axis)
        
        # Normalize directions (should already be normalized, but be safe)
        forward_dir_norm = np.linalg.norm(forward_dir)
        right_dir_norm = np.linalg.norm(right_dir)
        if forward_dir_norm > 1e-6:
            forward_dir = forward_dir / forward_dir_norm
        else:
            forward_dir = np.array([0, 0, 1])
        if right_dir_norm > 1e-6:
            right_dir = right_dir / right_dir_norm
        else:
            right_dir = np.array([1, 0, 0])
        
        # Calculate desired acceleration based on active keys
        desired_forward_accel = 0.0
        desired_right_accel = 0.0
        
        if 'w' in active_keys:
            desired_forward_accel += acceleration_rate
        if 's' in active_keys:
            desired_forward_accel -= acceleration_rate
        if 'a' in active_keys:
            desired_right_accel -= acceleration_rate  # Left is negative right
        if 'd' in active_keys:
            desired_right_accel += acceleration_rate  # Right is positive right
        
        # Update velocity with acceleration and damping
        velocity_change = np.array([0.0, 0.0, 0.0])
        if abs(desired_forward_accel) > 0.01:
            velocity_change += forward_dir * desired_forward_accel * dt
        if abs(desired_right_accel) > 0.01:
            velocity_change += right_dir * desired_right_accel * dt
        
        if np.linalg.norm(velocity_change) > 1e-6:
            # Accelerate in desired direction
            current_velocity += velocity_change
            
            # Clamp velocity magnitude
            velocity_magnitude = np.linalg.norm(current_velocity)
            if velocity_magnitude > max_velocity:
                current_velocity = current_velocity / velocity_magnitude * max_velocity
        else:
            # Apply damping when no input
            current_velocity *= damping_factor
            if np.linalg.norm(current_velocity) < 0.001:
                current_velocity = np.array([0.0, 0.0, 0.0])
        
        # Update position based on velocity (rotation stays the same)
        new_pos = current_pos + current_velocity * dt
        
        # Create new transform with same rotation, updated position
        T0_new = T0.copy()
        T0_new[0:3, 3] = new_pos
        T0 = T0_new.astype(dtype=np.float32, order="F")
        
        # Update guizmo transform to match T0 when in keyboard mode (keeps it in sync, even if hidden)
        # This way when switching back to mouse mode, guizmo will be at the right position
        # Also ensure it stays hidden in keyboard mode
        if hasattr(viewer_base, 'guizmo') and control_mode == 'keyboard':
            viewer_base.guizmo.T = T0.copy()
            viewer_base.guizmo.visible = False  # Ensure it stays hidden

    def update_first_person_camera():
        """Update camera to follow above and behind fish (fake first-person / third-person view)"""
        # Get fish position and orientation from T0
        fish_pos = T0[0:3, 3]
        
        # Extract rotation matrix to get actual forward and up directions
        # This ensures we use the same coordinate system as the transform
        R = T0[0:3, 0:3]
        
        # Get forward direction from rotation matrix (Z-axis column)
        # This should match the forward direction used in movement
        fish_forward = R[:, 2].copy()
        fish_up = R[:, 1].copy()  # Y-axis is up
        
        # Normalize (should already be normalized, but be safe)
        fish_forward_norm = np.linalg.norm(fish_forward)
        fish_up_norm = np.linalg.norm(fish_up)
        if fish_forward_norm > 1e-6:
            fish_forward = fish_forward / fish_forward_norm
        if fish_up_norm > 1e-6:
            fish_up = fish_up / fish_up_norm
        
        # Position camera above and behind the fish (like a third-person camera)
        # Camera is positioned: behind the fish, above its head
        height_offset = 1.5  # Height above fish (above its head)  
        behind_distance = camera_distance  # Distance behind fish
        
        # Calculate camera position: behind fish, above fish's head
        # Behind: move opposite to forward direction
        camera_offset_back = -fish_forward * behind_distance
        # Above: move up along the up vector from the transform
        camera_offset_up = fish_up * height_offset
        camera_eye = fish_pos + camera_offset_back + camera_offset_up
        
        # Look at a point ahead of the fish (in the direction it's facing)
        # Look slightly ahead so we can see where the fish is going
        look_at_distance = 1.2  # How far ahead to look
        look_at_point = fish_pos + fish_forward * look_at_distance
        
        # Ensure coordinates are valid (not NaN or Inf)
        if np.any(np.isnan(camera_eye)) or np.any(np.isinf(camera_eye)):
            return
        if np.any(np.isnan(look_at_point)) or np.any(np.isinf(look_at_point)):
            return
        
        # Convert to row vectors (as expected by the viewer API - RowVector3d)
        # The API expects RowVector3d which is a 1x3 array
        camera_eye_row = camera_eye.reshape(1, 3) if camera_eye.ndim == 1 else camera_eye
        look_at_point_row = look_at_point.reshape(1, 3) if look_at_point.ndim == 1 else look_at_point
        
        # Ensure they're the right shape (1, 3)
        if camera_eye_row.shape != (1, 3):
            camera_eye_row = camera_eye_row.reshape(1, -1)[:, :3]
        if look_at_point_row.shape != (1, 3):
            look_at_point_row = look_at_point_row.reshape(1, -1)[:, :3]
        
        # Set camera
        viewer_base.set_camera_eye(camera_eye_row)
        viewer_base.set_camera_center(look_at_point_row)
    
    def update_third_person_camera():
        """Update camera to track fish in third-person mode"""
        # Get fish position and orientation from T0
        fish_pos = T0[0:3, 3]
        
        # Extract rotation matrix
        R = T0[0:3, 0:3]
        fish_forward = R[:, 2].copy()
        fish_up = R[:, 1].copy()
        
        # Normalize
        fish_forward_norm = np.linalg.norm(fish_forward)
        fish_up_norm = np.linalg.norm(fish_up)
        if fish_forward_norm > 1e-6:
            fish_forward = fish_forward / fish_forward_norm
        if fish_up_norm > 1e-6:
            fish_up = fish_up / fish_up_norm
        
        # Position camera above and behind fish, but much further back for third-person view
        height_offset = 3.0  # Higher up for third-person
        behind_distance = camera_distance * 2.5  # Much further back to see rotation clearly
        
        # Calculate camera position
        camera_offset_back = -fish_forward * behind_distance
        camera_offset_up = fish_up * height_offset
        camera_eye = fish_pos + camera_offset_back + camera_offset_up
        
        # Look at the fish (or slightly ahead)
        look_at_point = fish_pos + fish_forward * 0.3
        
        # Ensure coordinates are valid
        if np.any(np.isnan(camera_eye)) or np.any(np.isinf(camera_eye)):
            return
        if np.any(np.isnan(look_at_point)) or np.any(np.isinf(look_at_point)):
            return
        
        # Convert to row vectors
        camera_eye_row = camera_eye.reshape(1, 3) if camera_eye.ndim == 1 else camera_eye
        look_at_point_row = look_at_point.reshape(1, 3) if look_at_point.ndim == 1 else look_at_point
        
        if camera_eye_row.shape != (1, 3):
            camera_eye_row = camera_eye_row.reshape(1, -1)[:, :3]
        if look_at_point_row.shape != (1, 3):
            look_at_point_row = look_at_point_row.reshape(1, -1)[:, :3]
        
        # Set camera
        viewer_base.set_camera_eye(camera_eye_row)
        viewer_base.set_camera_center(look_at_point_row)

    step = 0
    def pre_draw_callback():
        nonlocal J, B, T0, sim, st, step, last_update_time
        
        current_time = time.time()
        dt = current_time - last_update_time
        if dt <= 0:
            dt = 0.016  # Prevent division by zero or negative dt
        last_update_time = current_time
        dt = min(dt, 0.1)  # Cap dt to prevent large jumps
        
        # Update controls based on control mode
        if control_mode == 'keyboard':
            # Keyboard control: update fish transform based on WASD input
            update_keyboard_controls(dt)
            # Ensure guizmo stays hidden in keyboard mode
            if hasattr(viewer_base, 'guizmo'):
                viewer_base.guizmo.visible = False
        else:
            # Mouse control: update T0 from guizmo (user is controlling via guizmo)
            if hasattr(viewer_base, 'guizmo') and viewer_base.guizmo.visible:
                T0 = viewer_base.guizmo.T.copy()
        
        # Update camera based on camera mode (independent of control mode)
        if camera_mode == 'first_person':
            update_first_person_camera()
        else:
            update_third_person_camera()
        
        # Update simulation
        p = T0[0:3, :].reshape((12, 1))
        z = sim.step(p, st)
        st.update(z, p)
        
        # Update viewer
        viewer_base.set_bone_transforms(p, z * (1.0 if vis_cd else 0.0), 0)
        viewer_base.updateGL(0)
        step += 1

    # Set callbacks
    viewer_base.set_pre_draw_callback(pre_draw_callback)
    viewer_base.set_key_callback(key_callback)
    
    # Launch viewer
    viewer_base.launch(60, True)

